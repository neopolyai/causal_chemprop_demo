{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import logging\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from astartes import train_test_split\n",
    "from chemprop import data as chemprop_data_utils\n",
    "from chemprop import featurizers, nn\n",
    "from lightning import pytorch as pl\n",
    "from lightning.pytorch import seed_everything\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "\n",
    "from causal_chemprop import SobolevMPNN, CustomMSEMetric\n",
    "from chemprop.nn.transforms import ScaleTransform, UnscaleTransform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 8675309\n",
    "TRAINING_FPATH = Path(\"../data/aurka.csv\")          # TODO: Update path\n",
    "\n",
    "# setup logging and output directories\n",
    "_output_dir = Path(f\"output/chemprop_{int(datetime.datetime.now(datetime.UTC).timestamp())}\")\n",
    "os.makedirs(_output_dir, exist_ok=True)\n",
    "logging.getLogger(\"pytorch_lightning\").setLevel(logging.INFO)\n",
    "seed_everything(RANDOM_SEED)\n",
    "\n",
    "downsample_percent = 1.0\n",
    "mpnn_hidden_size = 800\n",
    "fnn_hidden_size = 200"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the training data\n",
    "df = pd.read_csv(TRAINING_FPATH)\n",
    "if downsample_percent:\n",
    "    print(f\"Down-sampling training data to {downsample_percent:.2%} size!\")\n",
    "    downsample_df = df.copy()\n",
    "    downsample_df[\"original_index\"] = np.arange(len(df))\n",
    "    downsample_df = downsample_df.groupby([\"SMI\", \"MR_ID\"]).aggregate(list)\n",
    "    downsample_df = downsample_df.sample(frac=downsample_percent, replace=False, random_state=RANDOM_SEED)\n",
    "    chosen_indexes = downsample_df.explode(\"original_index\")[\"original_index\"].to_numpy().flatten().astype(int)\n",
    "    print(f\"Actual downsample percentage is {len(chosen_indexes)/len(df):.2%}, count: {len(chosen_indexes)}!\")\n",
    "    df = df.iloc[chosen_indexes]\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# train-test split\n",
    "studies_train, studies_val = train_test_split(pd.unique(df[\"MR_ID\"]), random_state=RANDOM_SEED, train_size=0.8, test_size=0.2)\n",
    "train_indexes = df.index[df[\"MR_ID\"].isin(studies_train)].tolist()\n",
    "val_indexes = df.index[df[\"MR_ID\"].isin(studies_val)].tolist()\n",
    "test_indexes = val_indexes[len(val_indexes)//2:]\n",
    "val_indexes = val_indexes[:len(val_indexes)//2]\n",
    "_total = len(df)\n",
    "print(f\"train: {len(train_indexes)} ({len(train_indexes)/_total:.0%}) validation:\" f\"{len(val_indexes)} ({len(val_indexes)/_total:.0%}) test:\" f\"{len(test_indexes)} ({len(test_indexes)/_total:.0%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual re-scaling\n",
    "target_scaler = StandardScaler().fit(df[[\"logS\"]].iloc[train_indexes])\n",
    "scaled_logs = target_scaler.transform(df[[\"logS\"]]).ravel()\n",
    "all_data = [\n",
    "    chemprop_data_utils.MoleculeDatapoint.from_smi(smi, [log_s])\n",
    "    for smi, log_s in zip(df[\"SMI\"], scaled_logs)\n",
    "]\n",
    "# create datasets and dataloaders\n",
    "train_data, val_data, _ = chemprop_data_utils.split_data_by_indices(all_data, train_indices=train_indexes, val_indices=val_indexes)\n",
    "featurizer = featurizers.SimpleMoleculeMolGraphFeaturizer()\n",
    "train_datasets = chemprop_data_utils.MoleculeDataset(train_data, featurizer) \n",
    "val_datasets = chemprop_data_utils.MoleculeDataset(val_data, featurizer) \n",
    "causal_datasets = chemprop_data_utils.MoleculeDataset(train_data, featurizer) \n",
    "train_loader = chemprop_data_utils.build_dataloader(train_datasets, batch_size=64, num_workers=1, persistent_workers=True, shuffle=True)\n",
    "val_loader = chemprop_data_utils.build_dataloader(val_datasets, batch_size=16, num_workers=1, persistent_workers=True, shuffle=False)\n",
    "causal_loader = chemprop_data_utils.build_dataloader(causal_datasets, batch_size=16, num_workers=1, persistent_workers=True, shuffle=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build Chemprop\n",
    "mcmp = nn.BondMessagePassing(\n",
    "    depth=3, \n",
    "    d_h=mpnn_hidden_size, \n",
    "    dropout=0.50\n",
    ") \n",
    "agg = nn.MeanAggregation()\n",
    "output_transform = UnscaleTransform.from_standard_scaler(target_scaler)\n",
    "ffn = nn.RegressionFFN(\n",
    "    input_dim=mcmp.output_dim,  \n",
    "    hidden_dim=fnn_hidden_size,\n",
    "    dropout=0.50,\n",
    "    n_layers=4,\n",
    "    criterion=CustomMSEMetric(),\n",
    "    output_transform=output_transform,\n",
    ")\n",
    "metric_list = [CustomMSEMetric()]\n",
    "mcmpnn = SobolevMPNN(\n",
    "    fnn_hidden_size + 1,  # +1 for solubility\n",
    "    _output_dir,\n",
    "    mcmp,\n",
    "    agg,\n",
    "    ffn,\n",
    "    batch_norm=True,\n",
    "    metrics=metric_list,\n",
    "    init_lr=0.00001,     \n",
    "    max_lr=0.0001,\n",
    "    final_lr=0.00001,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure trainer\n",
    "tensorboard_logger = TensorBoardLogger(\n",
    "    _output_dir,\n",
    "    name=\"tensorboard_logs\",\n",
    "    default_hp_metric=False,\n",
    ")\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor=\"val/logs_loss\",  # don't condition on neopoly loss, use FNN loss instead\n",
    "        mode=\"min\",\n",
    "        verbose=False,\n",
    "        patience=10,\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        monitor=\"val/logs_loss\",\n",
    "        dirpath=os.path.join(_output_dir, \"checkpoints\"),\n",
    "        save_top_k=1,\n",
    "        mode=\"min\",\n",
    "    ),\n",
    "]\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=200,           \n",
    "    logger=tensorboard_logger,\n",
    "    log_every_n_steps=1,\n",
    "    enable_checkpointing=True,\n",
    "    check_val_every_n_epoch=1,\n",
    "    callbacks=callbacks,\n",
    "    num_sanity_val_steps=0,\n",
    "    inference_mode=False,       # to enable sobolev\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit MCMPNN and causal model\n",
    "trainer.fit(mcmpnn, train_loader, val_loader)\n",
    "ckpt_path = trainer.checkpoint_callback.best_model_path\n",
    "mcmpnn = mcmpnn.__class__.load_from_checkpoint(ckpt_path)\n",
    "mcmpnn.fit_causal(causal_loader, causal_loader)\n",
    "torch.save(mcmpnn, _output_dir / \"chemprop_model.pt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.manifold import TSNE\n",
    "from lightning.pytorch import Trainer\n",
    "\n",
    "from causal_chemprop import SobolevMPNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parity_plot(truth, prediction, title):\n",
    "    r, _ = pearsonr(truth, prediction)\n",
    "    mse = mean_squared_error(truth, prediction)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(truth, prediction)\n",
    "    wn_07 = np.count_nonzero(np.abs(truth - prediction) <= 0.7) / len(prediction)\n",
    "    wn_1 = np.count_nonzero(np.abs(truth - prediction) <= 1.0) / len(prediction)\n",
    "\n",
    "    stat_str = f\" - Pearson's r: {r:.4f}\\n - RMSE: {rmse:.4f}\"\n",
    "    plt.clf()\n",
    "    plt.scatter(\n",
    "        truth, prediction,\n",
    "        alpha=0.5,              # increase transparency to make points more visible\n",
    "        s=25,                   # slightly larger markers\n",
    "        edgecolors='black',     # remove outlines for better density visualization\n",
    "        facecolors='blue',      # fill color\n",
    "        marker='o'\n",
    "    )\n",
    "    plt.tick_params(axis='both', which='major', labelsize=12)\n",
    "    plt.xlabel(\"Actual IC50 values\", fontsize=14)\n",
    "    plt.ylabel(\"Predicted IC50 values\", fontsize=14)\n",
    "    min_val = min(np.min(truth), np.min(prediction)) - 0.5\n",
    "    max_val = max(np.max(truth), np.max(prediction)) + 0.5\n",
    "    plt.plot([min_val, max_val], [min_val, max_val], color=\"black\", linestyle=\"-\")\n",
    "    plt.plot([min_val, max_val], [min_val + 1, max_val + 1], color=\"red\", linestyle=\"--\", alpha=0.3)\n",
    "    plt.plot([min_val, max_val], [min_val - 1, max_val - 1], color=\"red\", linestyle=\"--\", alpha=0.3)\n",
    "    plt.xlim(min_val, max_val)\n",
    "    plt.ylim(min_val, max_val)\n",
    "    plt.text(\n",
    "        min_val, max_val - 0.1, stat_str,\n",
    "        ha=\"left\", va=\"top\",\n",
    "        fontsize=14,\n",
    "        bbox=dict(facecolor='white', alpha=0.01, edgecolor='none')\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MCMPNN and causal model\n",
    "ckpt_path = Path(\"output/chemprop_aurka8020/checkpoints/epoch=61-step=682.ckpt\")        # TODO: Update path\n",
    "causal_pkl = Path(\"output/chemprop_aurka8020/causal_model.pkl\")                         # TODO: Update path\n",
    "model = SobolevMPNN.load_from_checkpoint(\n",
    "    ckpt_path, \n",
    "    causal_pkl=causal_pkl\n",
    ")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test _causal_inference\n",
    "for holdout_fpath in (     \n",
    "    Path(\"../data/aurka.csv\"),          # TODO: Update path\n",
    "):\n",
    "    df = pd.read_csv(holdout_fpath)\n",
    "    df = df.loc[test_indexes]\n",
    "    test_datapoints = [chemprop_data_utils.MoleculeDatapoint.from_smi(smi, None, x_d=None) for smi in df[\"SMI\"]]\n",
    "    featurizer = featurizers.SimpleMoleculeMolGraphFeaturizer()\n",
    "    test_datasets = chemprop_data_utils.MoleculeDataset(test_datapoints, featurizer)\n",
    "    test_loader = chemprop_data_utils.build_dataloader(test_datasets, shuffle=False)\n",
    "    trainer = Trainer(logger=False)\n",
    "    predictions = np.concatenate(trainer.predict(model, test_loader), axis=0)\n",
    "    parity_plot(df[\"logS\"], predictions, holdout_fpath.stem)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "causal_chemprop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
